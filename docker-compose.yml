version: '1.0'

services:
  llama-server:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: llama-server
    volumes:
      - ./models:/llama.cpp/models
    ports:
      - "8080:8080"
    restart: always


